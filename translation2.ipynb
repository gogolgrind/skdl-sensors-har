{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GxYZPN6DVbJj",
    "outputId": "0da49516-3cea-4aa8-c41d-8e865e349123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLGm_uy8YSWY"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/drive/My Drive/Skeleton.zip', 'r')\n",
    "zip_ref.extractall('./')\n",
    "\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Oqpibc4YbMr"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhsoYUsaYdn1"
   },
   "outputs": [],
   "source": [
    "#https://github.com/woo-chia-wei/kinect-sequence-classification\n",
    "def import_skeleton_data(action, subject, trial):\n",
    "    filename = f'Skeleton/a{action}_s{subject}_t{trial}_skeleton.mat'\n",
    "    #print(Path(filename).is_file())\n",
    "    #if Path(filename).is_file():\n",
    "    mat = scipy.io.loadmat(filename)\n",
    "    return mat['d_skel']\n",
    "  #  else:\n",
    "  #      return None\n",
    "\n",
    "def transform_skeleton_data(action, subject, trial):\n",
    "    matrices = []\n",
    "    data = import_skeleton_data(action, subject, trial)\n",
    "    #print(data.shape)\n",
    "    if data is None: return None\n",
    "    #print(data[:,0,0])\n",
    "    for frame in range(data.shape[2]):\n",
    "        skelecton_joints = [i + 1 for i in range(20)]\n",
    "        matrix = data[:,:,frame]\n",
    "        matrix = np.insert(matrix, 0, skelecton_joints, axis=1)\n",
    "        matrix = np.insert(matrix, 0, frame, axis=1)\n",
    "        matrices.append(matrix)\n",
    "    result = np.vstack(tuple(matrices))\n",
    "    result = np.insert(result, 0, [[action], [subject], [trial]], axis=1)\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "def transform_skeleton_data_to_df(action, subject, trial):\n",
    "    data = transform_skeleton_data(action, subject, trial)\n",
    "    #print(data.shape)\n",
    "    if data is None: return None\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['action', 'subject', 'trial', 'frame', 'skeleton_joint', 'x', 'y', 'z']\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGkLNKGZe_s5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_columns = ['head','shoulder_center', 'spine','hip_center' ,'left_shoulder','left_elbow','left_wrist','left_hand','right_shoulder','right_elbow','right_wrist','right_hand','left_hip',\n",
    "              'left_knee','left_ankle','left_foot','right_hip','right_knee','right_ankle','right_foot' ]\n",
    "columns = data_columns + ['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJjXyDljYjJA"
   },
   "outputs": [],
   "source": [
    "def change_data(frame):\n",
    "    keys = np.array(frame['skeleton_joint'])\n",
    "    joint = 1\n",
    "    dfx = pd.DataFrame(columns = columns)\n",
    "    dfy = pd.DataFrame(columns = columns)\n",
    "    dfz = pd.DataFrame(columns = columns)\n",
    "    dfx['action'] = frame['action']\n",
    "    dfy['action'] = frame['action']\n",
    "    dfz['action'] = frame['action']\n",
    "    for i in range(len(data_columns)):\n",
    "       \n",
    "        #print(i)\n",
    "        dfx[data_columns[i]] = np.array(frame.x)* np.where(keys ==joint, keys, 0)\n",
    "        #print(i)\n",
    "        \n",
    "        dfy[data_columns[i]] = np.array(frame.y)* np.where(keys ==joint, keys, 0)\n",
    "\n",
    "        \n",
    "        dfz[data_columns[i]] = np.array(frame.z)* np.where(keys ==joint, keys, 0)\n",
    "        joint += 1\n",
    "   \n",
    "    return dfx, dfy, dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rh2AtijBkem3"
   },
   "outputs": [],
   "source": [
    "subjects_x = []\n",
    "subjects_y = []\n",
    "subjects_z = []\n",
    "for a in range(1,28):\n",
    "    for s in range(1,9):\n",
    "        for t in range(1,5):\n",
    "            try:\n",
    "                df = transform_skeleton_data_to_df(a, s, t)\n",
    "                #print(len(df))\n",
    "                dfx, dfy, dfz = change_data(df)\n",
    "                subjects_x.append(dfx)\n",
    "                subjects_y.append(dfy)\n",
    "                subjects_z.append(dfz)\n",
    "            except FileNotFoundError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfZIL75Nllli"
   },
   "outputs": [],
   "source": [
    "def reduce(list_of_df):\n",
    "    new_subjects = []\n",
    "    for df in list_of_df:\n",
    "        assert(len(df.action.unique()) == 1)\n",
    "\n",
    "\n",
    "        new = pd.DataFrame(columns = list(df))\n",
    "\n",
    "        for col in list(df):\n",
    "            if col != 'action':\n",
    "                dat = np.array(df[col])\n",
    "                dat = dat[dat != 0.]\n",
    "                new[col] = dat\n",
    "        new['action'] = df.action.unique()[0]\n",
    "        new_subjects.append(new)\n",
    "    return new_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7jHfnLRnJzT"
   },
   "outputs": [],
   "source": [
    "list_x = reduce(subjects_x)\n",
    "list_y = reduce(subjects_y)\n",
    "list_z = reduce(subjects_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Osf1qAt2nauW"
   },
   "outputs": [],
   "source": [
    "\n",
    "cat_np = []\n",
    "targets = np.array([])\n",
    "for i in range(len(list_x)):\n",
    "    df = list_x[i].append(list_y[i], ignore_index =True)\n",
    "    df = df.append(list_z[i], ignore_index = True)\n",
    "    assert(len(df.action.unique()) == 1)\n",
    "    targets = np.append(targets, df.action.unique()[0])\n",
    "    df = df.drop(['action'], axis=1)\n",
    "    cat_np.append(df.T.to_numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05CqxncXpEIb"
   },
   "outputs": [],
   "source": [
    "max_frames = 0\n",
    "min_frames = 400\n",
    "ave = 0\n",
    "for i in range(len(cat_np)):\n",
    "    t = cat_np[i].shape[1]\n",
    "    if t > max_frames:\n",
    "        max_frames = t\n",
    "    if t < min_frames:\n",
    "        min_frames = t\n",
    "    ave += t\n",
    "ave = ave / len(cat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EOITfvzap-Kb",
    "outputId": "f72427e4-bcef-4cf0-8737-0f3ab54263a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 123, 203.13240418118468)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frames, min_frames, ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33wZIMAHqEK8"
   },
   "outputs": [],
   "source": [
    "transformed_data = []\n",
    "for video in cat_np:\n",
    "    \n",
    "    if video.shape[1] > 201:\n",
    "        video = video[:, :201]\n",
    "    \n",
    "    c_min = np.amin(video, axis=1, keepdims=True)\n",
    "    c_max = np.amax(video, axis=1, keepdims=True)\n",
    "    max_k = np.amax(c_max - c_min)\n",
    "    P = np.floor(255. * (video - c_min) / max_k)\n",
    "    #print( max_k)\n",
    "    if P.shape[1] < 201:\n",
    "        zeros = np.zeros((P.shape[0], 201- P.shape[1]))\n",
    "        P = np.hstack((P, zeros))\n",
    "    transformed_data.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfFrYdIHEGuc"
   },
   "outputs": [],
   "source": [
    "targets -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "K6uQahBbkIjw",
    "outputId": "aaa40a34-0b77-4f66-dea5-54789aab086f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e57b6cf28>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAABECAYAAABkkEX6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(transformed_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rr5bOGai3wC"
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomBrightnessContrast,    \n",
    "    RandomGamma    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6kjmYrDiGxm"
   },
   "outputs": [],
   "source": [
    "new = []\n",
    "mask = []\n",
    "for i in range(len(transformed_data)):\n",
    "#i = 0\n",
    "    image = transformed_data[i]\n",
    "    label = targets[i]\n",
    "   \n",
    " \n",
    "    aug = HorizontalFlip(p=1)\n",
    "\n",
    "    augmented = aug(image=image)\n",
    "    image_h_flipped = augmented['image']\n",
    "\n",
    "    new.append(image_h_flipped)\n",
    "    \n",
    "    mask.append(label)\n",
    "   \n",
    "    aug = VerticalFlip(p=1)\n",
    "\n",
    "    augmented = aug(image=image)\n",
    "\n",
    "    image_v_flipped = augmented['image']\n",
    "    new.append(image_v_flipped)\n",
    "    \n",
    "    mask.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GmmM2AdlA7u"
   },
   "outputs": [],
   "source": [
    "transformed_data += new\n",
    "#targets += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ao3JROjlqOe"
   },
   "outputs": [],
   "source": [
    "mask = np.array(mask)\n",
    "targets=  np.append(targets, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HWeHe1TomB9V",
    "outputId": "26503784-4112-4e40-8e30-ed070fbc7136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXEKQ6gs2cdL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from google.colab import files\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbOAsbGz33-e"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.utils.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  \n",
    "    def __init__(self, data, targets, fold='train'):\n",
    "        self.fold = fold\n",
    "      \n",
    "        \n",
    "\n",
    "        X_train, X_, y_train, y_ = train_test_split( data, targets, train_size=0.7, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.6, random_state=42)\n",
    "        self.train_data = torch.FloatTensor(X_train)\n",
    "        self.train_labels = torch.LongTensor(y_train)\n",
    "        \n",
    "        self.val_data = torch.FloatTensor(X_val)\n",
    "        self.val_labels = torch.LongTensor(y_val)\n",
    "        self.test_data = torch.FloatTensor(X_test)\n",
    "        self.test_labels = torch.LongTensor(y_test)\n",
    "      \n",
    "    def __len__(self):\n",
    "        if self.fold == 'train':\n",
    "            return len(self.train_data)\n",
    "        elif self.fold == 'val':\n",
    "            return len(self.val_data)\n",
    "        elif self.fold == 'test':\n",
    "            return len(self.test_data)\n",
    "     \n",
    "            \n",
    "  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      \n",
    "        if self.fold == 'train':\n",
    "            data = self.train_data[index]\n",
    "            label =  self.train_labels[index]\n",
    "        elif self.fold == 'val':\n",
    "            data = self.val_data[index]\n",
    "            label =  self.val_labels[index]\n",
    "        elif self.fold == 'test':\n",
    "            data = self.test_data[index]\n",
    "            label =  self.test_labels[index]\n",
    "        return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3ezj-SdDzEQ"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(transformed_data, targets,fold='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yGlg1uaEEUB"
   },
   "outputs": [],
   "source": [
    "val_dataset = Dataset(transformed_data, targets,fold='val')\n",
    "test_dataset = Dataset(transformed_data, targets,fold='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LF1hDaYWE81o",
    "outputId": "80847bab-b75e-4f3b-b3df-dcc775a8cf55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808 465 310\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-s2pCHVdELTS"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=50,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=50,shuffle=False)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=50,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REd-GM2_FnVx"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dvmJJ5KnXixV",
    "outputId": "4cb95cb8-c3d9-4b1c-8b8e-8e1702c41d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.3.0\n"
     ]
    }
   ],
   "source": [
    "#https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/finetuning_torchvision_models_tutorial.ipynb#scrollTo=XVeRWfblXYOY\n",
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6xwY8aujJel"
   },
   "outputs": [],
   "source": [
    "# Number of classes in the dataset\n",
    "num_classes = 27\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 50\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Be4mxqvCjVs_"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \"\"\"\n",
    "                inputs = torch.transpose(inputs, 1, 2)\n",
    "                inputs = nn.Linear(20,3)(inputs)\n",
    "                inputs = torch.transpose(inputs, 1, 2)\n",
    "                inputs = inputs.unsqueeze(3)\\\n",
    "                \"\"\"\n",
    "                #print(inputs.shape)\n",
    "                try:\n",
    "                    inputs = inputs.view(50, 3, 20, 67)\n",
    "                except RuntimeError:\n",
    "                    inputs = inputs.view(-1, 3, 20, 67)\n",
    "                inputs = inputs.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        #print(outputs.shape)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GI4jyXKlkM5Y"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "G-yn7qmYkg5r",
    "outputId": "898c2b8a-af6d-41c6-ea67-7e25eba8570f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/checkpoints/vgg11_bn-6002323d.pth\n",
      "100%|██████████| 531503671/531503671 [00:17<00:00, 29694219.86it/s]\n"
     ]
    }
   ],
   "source": [
    "def initialize_model( model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        \n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(\"vgg\", num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#Tprint(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "eGwylb11lOK6",
    "outputId": "fdfe2476-341c-423b-bd6f-2ccfd41b9caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.0.weight\n",
      "\t features.0.bias\n",
      "\t features.1.weight\n",
      "\t features.1.bias\n",
      "\t features.4.weight\n",
      "\t features.4.bias\n",
      "\t features.5.weight\n",
      "\t features.5.bias\n",
      "\t features.8.weight\n",
      "\t features.8.bias\n",
      "\t features.9.weight\n",
      "\t features.9.bias\n",
      "\t features.11.weight\n",
      "\t features.11.bias\n",
      "\t features.12.weight\n",
      "\t features.12.bias\n",
      "\t features.15.weight\n",
      "\t features.15.bias\n",
      "\t features.16.weight\n",
      "\t features.16.bias\n",
      "\t features.18.weight\n",
      "\t features.18.bias\n",
      "\t features.19.weight\n",
      "\t features.19.bias\n",
      "\t features.22.weight\n",
      "\t features.22.bias\n",
      "\t features.23.weight\n",
      "\t features.23.bias\n",
      "\t features.25.weight\n",
      "\t features.25.bias\n",
      "\t features.26.weight\n",
      "\t features.26.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Send the model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.0004, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42551
    },
    "colab_type": "code",
    "id": "PuZjb_EUmP4f",
    "outputId": "9a5be447-6490-4d90-8c07-1fc3dfc71774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 3.2991 Acc: 0.0465\n",
      "val Loss: 3.2372 Acc: 0.1161\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 3.1824 Acc: 0.1051\n",
      "val Loss: 3.0980 Acc: 0.1613\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 2.9695 Acc: 0.1753\n",
      "val Loss: 2.8674 Acc: 0.2065\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 2.6776 Acc: 0.2489\n",
      "val Loss: 2.5882 Acc: 0.2409\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 2.3604 Acc: 0.3330\n",
      "val Loss: 2.3158 Acc: 0.3247\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 2.0307 Acc: 0.4110\n",
      "val Loss: 2.0424 Acc: 0.3763\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 1.7674 Acc: 0.4867\n",
      "val Loss: 1.8247 Acc: 0.4151\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 1.4851 Acc: 0.5431\n",
      "val Loss: 1.6341 Acc: 0.4559\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 1.2581 Acc: 0.6167\n",
      "val Loss: 1.5072 Acc: 0.4968\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 1.0906 Acc: 0.6692\n",
      "val Loss: 1.3605 Acc: 0.5290\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.9444 Acc: 0.6975\n",
      "val Loss: 1.3309 Acc: 0.5312\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.8061 Acc: 0.7555\n",
      "val Loss: 1.1940 Acc: 0.6065\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.6838 Acc: 0.7931\n",
      "val Loss: 1.1644 Acc: 0.5871\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.5873 Acc: 0.8213\n",
      "val Loss: 1.0810 Acc: 0.6387\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.5184 Acc: 0.8429\n",
      "val Loss: 1.1083 Acc: 0.6258\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.4719 Acc: 0.8496\n",
      "val Loss: 1.0622 Acc: 0.6215\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.4360 Acc: 0.8612\n",
      "val Loss: 1.0235 Acc: 0.6581\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.4214 Acc: 0.8628\n",
      "val Loss: 0.9428 Acc: 0.6882\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.3493 Acc: 0.8966\n",
      "val Loss: 1.0227 Acc: 0.6452\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.3229 Acc: 0.8971\n",
      "val Loss: 1.0370 Acc: 0.6624\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.3503 Acc: 0.8844\n",
      "val Loss: 1.0585 Acc: 0.6796\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.2720 Acc: 0.9181\n",
      "val Loss: 0.9389 Acc: 0.6925\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.2604 Acc: 0.9237\n",
      "val Loss: 0.9324 Acc: 0.7140\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.2216 Acc: 0.9375\n",
      "val Loss: 1.0309 Acc: 0.6817\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.9386\n",
      "val Loss: 0.9613 Acc: 0.7226\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1964 Acc: 0.9430\n",
      "val Loss: 0.9301 Acc: 0.7118\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.1678 Acc: 0.9497\n",
      "val Loss: 0.9410 Acc: 0.7011\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.1912 Acc: 0.9403\n",
      "val Loss: 1.0025 Acc: 0.6817\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9331\n",
      "val Loss: 1.0337 Acc: 0.7054\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.1210 Acc: 0.9668\n",
      "val Loss: 0.9960 Acc: 0.7183\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1114 Acc: 0.9707\n",
      "val Loss: 0.9395 Acc: 0.7140\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1118 Acc: 0.9729\n",
      "val Loss: 1.0014 Acc: 0.7140\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9425\n",
      "val Loss: 1.1744 Acc: 0.6925\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1232 Acc: 0.9635\n",
      "val Loss: 0.9996 Acc: 0.7333\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1710 Acc: 0.9463\n",
      "val Loss: 0.9565 Acc: 0.7312\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9580\n",
      "val Loss: 1.0110 Acc: 0.7054\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9674\n",
      "val Loss: 0.9716 Acc: 0.7269\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1565 Acc: 0.9502\n",
      "val Loss: 0.9782 Acc: 0.7247\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9701\n",
      "val Loss: 0.9361 Acc: 0.7376\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1223 Acc: 0.9629\n",
      "val Loss: 0.9988 Acc: 0.7204\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.1116 Acc: 0.9624\n",
      "val Loss: 0.9217 Acc: 0.7312\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1028 Acc: 0.9701\n",
      "val Loss: 1.0263 Acc: 0.7161\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0754 Acc: 0.9740\n",
      "val Loss: 0.9528 Acc: 0.7505\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9834\n",
      "val Loss: 0.9274 Acc: 0.7484\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9646\n",
      "val Loss: 1.0156 Acc: 0.7527\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0836 Acc: 0.9779\n",
      "val Loss: 0.9590 Acc: 0.7333\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0520 Acc: 0.9851\n",
      "val Loss: 0.9092 Acc: 0.7441\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0843 Acc: 0.9746\n",
      "val Loss: 1.0072 Acc: 0.7419\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.9873\n",
      "val Loss: 0.9599 Acc: 0.7699\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0410 Acc: 0.9884\n",
      "val Loss: 0.9973 Acc: 0.7505\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.9912\n",
      "val Loss: 1.0380 Acc: 0.7548\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0261 Acc: 0.9961\n",
      "val Loss: 0.9569 Acc: 0.7570\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9934\n",
      "val Loss: 1.0150 Acc: 0.7398\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0365 Acc: 0.9895\n",
      "val Loss: 1.0444 Acc: 0.7398\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0920 Acc: 0.9735\n",
      "val Loss: 1.1209 Acc: 0.7226\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1176 Acc: 0.9640\n",
      "val Loss: 1.0724 Acc: 0.7355\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0571 Acc: 0.9851\n",
      "val Loss: 1.0079 Acc: 0.7484\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0509 Acc: 0.9845\n",
      "val Loss: 1.0408 Acc: 0.7527\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0642 Acc: 0.9801\n",
      "val Loss: 1.0793 Acc: 0.7419\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9751\n",
      "val Loss: 1.0792 Acc: 0.7247\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0482 Acc: 0.9900\n",
      "val Loss: 1.0695 Acc: 0.7376\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0425 Acc: 0.9895\n",
      "val Loss: 1.0651 Acc: 0.7419\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 0.9950\n",
      "val Loss: 1.1488 Acc: 0.7398\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0224 Acc: 0.9956\n",
      "val Loss: 1.0086 Acc: 0.7785\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0330 Acc: 0.9900\n",
      "val Loss: 1.0191 Acc: 0.7591\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0360 Acc: 0.9917\n",
      "val Loss: 1.0161 Acc: 0.7720\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9917\n",
      "val Loss: 0.9904 Acc: 0.7785\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9845\n",
      "val Loss: 0.9923 Acc: 0.7656\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9784\n",
      "val Loss: 1.0561 Acc: 0.7591\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 0.9829\n",
      "val Loss: 1.0020 Acc: 0.7591\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0521 Acc: 0.9851\n",
      "val Loss: 1.1148 Acc: 0.7527\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0487 Acc: 0.9856\n",
      "val Loss: 1.0018 Acc: 0.7505\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0950 Acc: 0.9712\n",
      "val Loss: 1.1171 Acc: 0.7226\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0358 Acc: 0.9906\n",
      "val Loss: 1.0465 Acc: 0.7505\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0412 Acc: 0.9867\n",
      "val Loss: 1.0725 Acc: 0.7613\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9934\n",
      "val Loss: 1.0500 Acc: 0.7570\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.0318 Acc: 0.9928\n",
      "val Loss: 1.0470 Acc: 0.7462\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9956\n",
      "val Loss: 1.0325 Acc: 0.7505\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.0222 Acc: 0.9939\n",
      "val Loss: 1.0638 Acc: 0.7548\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.0442 Acc: 0.9867\n",
      "val Loss: 1.0579 Acc: 0.7376\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.0846 Acc: 0.9795\n",
      "val Loss: 1.1279 Acc: 0.7441\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.0575 Acc: 0.9823\n",
      "val Loss: 0.9600 Acc: 0.7677\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.0415 Acc: 0.9895\n",
      "val Loss: 1.0401 Acc: 0.7505\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9950\n",
      "val Loss: 0.9983 Acc: 0.7677\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.0417 Acc: 0.9889\n",
      "val Loss: 1.0157 Acc: 0.7548\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0524 Acc: 0.9845\n",
      "val Loss: 1.1222 Acc: 0.7376\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.0628 Acc: 0.9779\n",
      "val Loss: 1.0922 Acc: 0.7462\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.0552 Acc: 0.9851\n",
      "val Loss: 1.0283 Acc: 0.7527\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.9867\n",
      "val Loss: 0.9647 Acc: 0.7591\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9889\n",
      "val Loss: 0.9437 Acc: 0.7763\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 0.9923\n",
      "val Loss: 0.9917 Acc: 0.7763\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.0163 Acc: 0.9972\n",
      "val Loss: 1.0412 Acc: 0.7763\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1614 Acc: 0.9530\n",
      "val Loss: 1.0448 Acc: 0.7505\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.0571 Acc: 0.9812\n",
      "val Loss: 1.0263 Acc: 0.7656\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.0255 Acc: 0.9912\n",
      "val Loss: 0.9868 Acc: 0.7656\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.9906\n",
      "val Loss: 0.9971 Acc: 0.7699\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9950\n",
      "val Loss: 0.9404 Acc: 0.7742\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.0223 Acc: 0.9939\n",
      "val Loss: 0.9916 Acc: 0.7742\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9934\n",
      "val Loss: 0.9776 Acc: 0.7656\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.0151 Acc: 0.9972\n",
      "val Loss: 1.0174 Acc: 0.7699\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.0138 Acc: 0.9983\n",
      "val Loss: 1.0177 Acc: 0.7742\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.0129 Acc: 0.9978\n",
      "val Loss: 0.9906 Acc: 0.7742\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.0174 Acc: 0.9956\n",
      "val Loss: 1.0374 Acc: 0.7613\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.0235 Acc: 0.9923\n",
      "val Loss: 1.0539 Acc: 0.7677\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.0132 Acc: 0.9972\n",
      "val Loss: 1.0582 Acc: 0.7785\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.0152 Acc: 0.9950\n",
      "val Loss: 1.0567 Acc: 0.7677\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.9928\n",
      "val Loss: 1.0749 Acc: 0.7613\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.9900\n",
      "val Loss: 1.1656 Acc: 0.7527\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.0966 Acc: 0.9751\n",
      "val Loss: 1.1413 Acc: 0.7570\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.0572 Acc: 0.9795\n",
      "val Loss: 1.0746 Acc: 0.7462\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.0278 Acc: 0.9928\n",
      "val Loss: 1.1893 Acc: 0.7419\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.0402 Acc: 0.9912\n",
      "val Loss: 1.0807 Acc: 0.7634\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.0528 Acc: 0.9840\n",
      "val Loss: 1.1819 Acc: 0.7333\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9889\n",
      "val Loss: 1.0683 Acc: 0.7548\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.0372 Acc: 0.9900\n",
      "val Loss: 1.0564 Acc: 0.7548\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.0189 Acc: 0.9961\n",
      "val Loss: 1.0779 Acc: 0.7656\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.0107 Acc: 0.9983\n",
      "val Loss: 1.0457 Acc: 0.7806\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.0085 Acc: 0.9978\n",
      "val Loss: 1.1099 Acc: 0.7785\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.0091 Acc: 0.9989\n",
      "val Loss: 1.0959 Acc: 0.7742\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.0124 Acc: 0.9967\n",
      "val Loss: 1.1726 Acc: 0.7591\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 0.9923\n",
      "val Loss: 1.1500 Acc: 0.7548\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9917\n",
      "val Loss: 1.1043 Acc: 0.7656\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.0253 Acc: 0.9939\n",
      "val Loss: 1.0620 Acc: 0.7914\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.0271 Acc: 0.9934\n",
      "val Loss: 1.0754 Acc: 0.7742\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.0315 Acc: 0.9906\n",
      "val Loss: 1.1380 Acc: 0.7570\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.0196 Acc: 0.9961\n",
      "val Loss: 1.1392 Acc: 0.7591\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 0.9978\n",
      "val Loss: 1.1741 Acc: 0.7720\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.0150 Acc: 0.9967\n",
      "val Loss: 1.1761 Acc: 0.7548\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.0133 Acc: 0.9967\n",
      "val Loss: 1.1947 Acc: 0.7677\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.0138 Acc: 0.9967\n",
      "val Loss: 1.2061 Acc: 0.7785\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9939\n",
      "val Loss: 1.1329 Acc: 0.7548\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.0185 Acc: 0.9934\n",
      "val Loss: 1.1203 Acc: 0.7613\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.0441 Acc: 0.9889\n",
      "val Loss: 1.0727 Acc: 0.7677\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.0147 Acc: 0.9967\n",
      "val Loss: 1.0993 Acc: 0.7828\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.9939\n",
      "val Loss: 1.0218 Acc: 0.7742\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 0.9961\n",
      "val Loss: 1.0581 Acc: 0.7570\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.0188 Acc: 0.9967\n",
      "val Loss: 1.1560 Acc: 0.7656\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.0154 Acc: 0.9972\n",
      "val Loss: 1.1132 Acc: 0.7677\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.0078 Acc: 0.9978\n",
      "val Loss: 1.0455 Acc: 0.7656\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9983\n",
      "val Loss: 1.0910 Acc: 0.7828\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9939\n",
      "val Loss: 1.1277 Acc: 0.7763\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.0243 Acc: 0.9923\n",
      "val Loss: 1.1080 Acc: 0.7527\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.0132 Acc: 0.9972\n",
      "val Loss: 1.0988 Acc: 0.7828\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.0178 Acc: 0.9928\n",
      "val Loss: 1.1209 Acc: 0.7720\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.0289 Acc: 0.9928\n",
      "val Loss: 1.2418 Acc: 0.7570\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.0217 Acc: 0.9934\n",
      "val Loss: 1.1244 Acc: 0.7871\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.0126 Acc: 0.9961\n",
      "val Loss: 1.1507 Acc: 0.7720\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.0386 Acc: 0.9900\n",
      "val Loss: 1.0796 Acc: 0.7785\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9912\n",
      "val Loss: 1.1544 Acc: 0.7613\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.0125 Acc: 0.9961\n",
      "val Loss: 1.1681 Acc: 0.7570\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9983\n",
      "val Loss: 1.1147 Acc: 0.7570\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.0207 Acc: 0.9961\n",
      "val Loss: 1.2061 Acc: 0.7505\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.0268 Acc: 0.9917\n",
      "val Loss: 1.1393 Acc: 0.7484\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.0466 Acc: 0.9917\n",
      "val Loss: 1.1635 Acc: 0.7398\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.0534 Acc: 0.9851\n",
      "val Loss: 1.0989 Acc: 0.7591\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.0196 Acc: 0.9923\n",
      "val Loss: 1.1747 Acc: 0.7527\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.0647 Acc: 0.9884\n",
      "val Loss: 1.1160 Acc: 0.7527\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.0516 Acc: 0.9873\n",
      "val Loss: 1.0711 Acc: 0.7355\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.0253 Acc: 0.9945\n",
      "val Loss: 0.9841 Acc: 0.7720\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.0124 Acc: 0.9978\n",
      "val Loss: 0.9696 Acc: 0.7720\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.0094 Acc: 0.9989\n",
      "val Loss: 1.0118 Acc: 0.7742\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.9945\n",
      "val Loss: 1.0177 Acc: 0.7720\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.0261 Acc: 0.9900\n",
      "val Loss: 1.0580 Acc: 0.7634\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.0117 Acc: 0.9961\n",
      "val Loss: 0.9845 Acc: 0.7871\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.0271 Acc: 0.9917\n",
      "val Loss: 1.0381 Acc: 0.7828\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.0174 Acc: 0.9945\n",
      "val Loss: 1.0334 Acc: 0.7656\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 0.9956\n",
      "val Loss: 1.0685 Acc: 0.7677\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.0097 Acc: 0.9978\n",
      "val Loss: 1.0703 Acc: 0.7613\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.0094 Acc: 0.9978\n",
      "val Loss: 1.0625 Acc: 0.7720\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9978\n",
      "val Loss: 1.1789 Acc: 0.7634\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.0158 Acc: 0.9967\n",
      "val Loss: 1.1067 Acc: 0.7570\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9983\n",
      "val Loss: 1.0954 Acc: 0.7634\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9956\n",
      "val Loss: 1.1115 Acc: 0.7634\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.0157 Acc: 0.9945\n",
      "val Loss: 1.1391 Acc: 0.7570\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.9923\n",
      "val Loss: 1.1952 Acc: 0.7376\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.0216 Acc: 0.9928\n",
      "val Loss: 1.1639 Acc: 0.7484\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.0168 Acc: 0.9961\n",
      "val Loss: 1.0547 Acc: 0.7634\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.0376 Acc: 0.9895\n",
      "val Loss: 1.1016 Acc: 0.7613\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.0286 Acc: 0.9912\n",
      "val Loss: 1.0569 Acc: 0.7656\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9983\n",
      "val Loss: 1.0544 Acc: 0.7806\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9983\n",
      "val Loss: 1.0622 Acc: 0.7828\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.0069 Acc: 0.9989\n",
      "val Loss: 1.0710 Acc: 0.7720\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 0.9978\n",
      "val Loss: 1.0855 Acc: 0.7720\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 0.9978\n",
      "val Loss: 1.0115 Acc: 0.7763\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.9945\n",
      "val Loss: 1.0080 Acc: 0.7849\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9972\n",
      "val Loss: 1.0755 Acc: 0.7742\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 0.9978\n",
      "val Loss: 1.1233 Acc: 0.7763\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.0204 Acc: 0.9939\n",
      "val Loss: 1.0416 Acc: 0.7720\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.0159 Acc: 0.9961\n",
      "val Loss: 1.0204 Acc: 0.7849\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.0204 Acc: 0.9950\n",
      "val Loss: 1.0739 Acc: 0.7763\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9945\n",
      "val Loss: 1.0558 Acc: 0.7613\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.0133 Acc: 0.9950\n",
      "val Loss: 1.0483 Acc: 0.7806\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.0275 Acc: 0.9928\n",
      "val Loss: 1.2123 Acc: 0.7613\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.0197 Acc: 0.9939\n",
      "val Loss: 1.1740 Acc: 0.7677\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.0160 Acc: 0.9939\n",
      "val Loss: 1.0508 Acc: 0.7828\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.0404 Acc: 0.9917\n",
      "val Loss: 1.1077 Acc: 0.7806\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.0221 Acc: 0.9917\n",
      "val Loss: 0.9994 Acc: 0.7806\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.0173 Acc: 0.9956\n",
      "val Loss: 1.0592 Acc: 0.7742\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9961\n",
      "val Loss: 0.9738 Acc: 0.7957\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.0952 Acc: 0.9795\n",
      "val Loss: 1.0537 Acc: 0.7656\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.0566 Acc: 0.9862\n",
      "val Loss: 1.0693 Acc: 0.7699\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.0117 Acc: 0.9983\n",
      "val Loss: 1.0529 Acc: 0.7849\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9972\n",
      "val Loss: 1.0303 Acc: 0.7849\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.0188 Acc: 0.9950\n",
      "val Loss: 1.2214 Acc: 0.7677\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.0242 Acc: 0.9923\n",
      "val Loss: 0.9707 Acc: 0.8043\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.9939\n",
      "val Loss: 1.1041 Acc: 0.7935\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.0208 Acc: 0.9928\n",
      "val Loss: 0.9771 Acc: 0.7892\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 0.9900\n",
      "val Loss: 0.9999 Acc: 0.7699\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.0124 Acc: 0.9972\n",
      "val Loss: 1.0257 Acc: 0.7763\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9978\n",
      "val Loss: 0.9999 Acc: 0.7828\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 0.9994\n",
      "val Loss: 1.0049 Acc: 0.7806\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.0151 Acc: 0.9945\n",
      "val Loss: 1.1628 Acc: 0.7720\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.0190 Acc: 0.9956\n",
      "val Loss: 1.0870 Acc: 0.7785\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 0.9978\n",
      "val Loss: 1.1172 Acc: 0.7871\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9989\n",
      "val Loss: 1.0816 Acc: 0.7871\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 0.9989\n",
      "val Loss: 1.0394 Acc: 0.7892\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.0066 Acc: 0.9989\n",
      "val Loss: 1.0643 Acc: 0.7871\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.0172 Acc: 0.9972\n",
      "val Loss: 1.1510 Acc: 0.7828\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9983\n",
      "val Loss: 1.0821 Acc: 0.7935\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 0.9961\n",
      "val Loss: 1.0767 Acc: 0.8022\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 0.9967\n",
      "val Loss: 1.0518 Acc: 0.7785\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.0172 Acc: 0.9950\n",
      "val Loss: 1.0575 Acc: 0.7763\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.0118 Acc: 0.9956\n",
      "val Loss: 1.0539 Acc: 0.7935\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.0151 Acc: 0.9956\n",
      "val Loss: 1.0926 Acc: 0.7892\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.0156 Acc: 0.9956\n",
      "val Loss: 1.0582 Acc: 0.7849\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.0097 Acc: 0.9967\n",
      "val Loss: 1.0428 Acc: 0.7785\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9994\n",
      "val Loss: 1.0443 Acc: 0.7763\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.0062 Acc: 0.9983\n",
      "val Loss: 1.0378 Acc: 0.7849\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.0123 Acc: 0.9950\n",
      "val Loss: 1.1039 Acc: 0.7763\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.0161 Acc: 0.9961\n",
      "val Loss: 1.0639 Acc: 0.7785\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 0.9967\n",
      "val Loss: 1.0246 Acc: 0.7849\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.0160 Acc: 0.9956\n",
      "val Loss: 1.1299 Acc: 0.7699\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.9928\n",
      "val Loss: 1.0186 Acc: 0.7892\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.0071 Acc: 0.9983\n",
      "val Loss: 1.0378 Acc: 0.7935\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.0051 Acc: 0.9989\n",
      "val Loss: 1.0271 Acc: 0.8000\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.0101 Acc: 0.9972\n",
      "val Loss: 0.9791 Acc: 0.8000\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.0069 Acc: 0.9983\n",
      "val Loss: 1.0644 Acc: 0.7914\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 0.9956\n",
      "val Loss: 1.0932 Acc: 0.7828\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9989\n",
      "val Loss: 1.1115 Acc: 0.7849\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.0073 Acc: 0.9978\n",
      "val Loss: 1.0827 Acc: 0.7914\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.0062 Acc: 0.9983\n",
      "val Loss: 1.1003 Acc: 0.7763\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.0063 Acc: 0.9983\n",
      "val Loss: 1.0669 Acc: 0.7763\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.0079 Acc: 0.9978\n",
      "val Loss: 1.0295 Acc: 0.7806\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9983\n",
      "val Loss: 1.1069 Acc: 0.7785\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.0091 Acc: 0.9978\n",
      "val Loss: 1.0633 Acc: 0.7849\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.0056 Acc: 0.9989\n",
      "val Loss: 1.0400 Acc: 0.7957\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.0141 Acc: 0.9950\n",
      "val Loss: 1.1190 Acc: 0.7699\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.0063 Acc: 0.9983\n",
      "val Loss: 1.1289 Acc: 0.7828\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 0.9956\n",
      "val Loss: 1.0489 Acc: 0.8000\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.9884\n",
      "val Loss: 1.0478 Acc: 0.7914\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 0.9983\n",
      "val Loss: 1.0028 Acc: 0.7828\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.0157 Acc: 0.9967\n",
      "val Loss: 0.9990 Acc: 0.7849\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.0170 Acc: 0.9967\n",
      "val Loss: 1.0806 Acc: 0.8000\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.0076 Acc: 0.9978\n",
      "val Loss: 1.0589 Acc: 0.7935\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.0040 Acc: 0.9989\n",
      "val Loss: 1.0488 Acc: 0.7935\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.0034 Acc: 1.0000\n",
      "val Loss: 1.0478 Acc: 0.7957\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.0092 Acc: 0.9983\n",
      "val Loss: 1.0974 Acc: 0.7957\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 0.9934\n",
      "val Loss: 1.1107 Acc: 0.7871\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.0072 Acc: 0.9989\n",
      "val Loss: 1.0869 Acc: 0.7978\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.0074 Acc: 0.9967\n",
      "val Loss: 1.0954 Acc: 0.7892\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.0205 Acc: 0.9945\n",
      "val Loss: 1.1450 Acc: 0.7849\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.0122 Acc: 0.9956\n",
      "val Loss: 1.1413 Acc: 0.7806\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.0186 Acc: 0.9945\n",
      "val Loss: 1.2213 Acc: 0.7656\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.0456 Acc: 0.9884\n",
      "val Loss: 1.2184 Acc: 0.7785\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9928\n",
      "val Loss: 1.1552 Acc: 0.7677\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 0.9972\n",
      "val Loss: 1.0707 Acc: 0.7828\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9978\n",
      "val Loss: 1.0601 Acc: 0.7849\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.0111 Acc: 0.9972\n",
      "val Loss: 1.0515 Acc: 0.7935\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9928\n",
      "val Loss: 1.1432 Acc: 0.7785\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9939\n",
      "val Loss: 1.0089 Acc: 0.7935\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.0602 Acc: 0.9889\n",
      "val Loss: 1.0087 Acc: 0.7892\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 0.9878\n",
      "val Loss: 0.9576 Acc: 0.8129\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9956\n",
      "val Loss: 0.9767 Acc: 0.7935\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 0.9906\n",
      "val Loss: 1.0947 Acc: 0.7871\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.0232 Acc: 0.9945\n",
      "val Loss: 0.9863 Acc: 0.7763\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.0424 Acc: 0.9884\n",
      "val Loss: 0.9943 Acc: 0.7806\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9945\n",
      "val Loss: 1.0066 Acc: 0.7871\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.0083 Acc: 0.9989\n",
      "val Loss: 0.9821 Acc: 0.7849\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.0063 Acc: 0.9989\n",
      "val Loss: 1.0367 Acc: 0.7785\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.0072 Acc: 0.9983\n",
      "val Loss: 0.9770 Acc: 0.7935\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.0076 Acc: 0.9972\n",
      "val Loss: 0.9464 Acc: 0.8108\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.0776 Acc: 0.9801\n",
      "val Loss: 1.1310 Acc: 0.7613\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.0337 Acc: 0.9928\n",
      "val Loss: 1.0345 Acc: 0.7699\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.0203 Acc: 0.9912\n",
      "val Loss: 0.9893 Acc: 0.7828\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.0075 Acc: 0.9983\n",
      "val Loss: 0.9618 Acc: 0.7849\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.0119 Acc: 0.9967\n",
      "val Loss: 1.0639 Acc: 0.7785\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 0.9967\n",
      "val Loss: 0.9974 Acc: 0.7957\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.9895\n",
      "val Loss: 1.0825 Acc: 0.7828\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 0.9961\n",
      "val Loss: 1.0691 Acc: 0.7742\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9950\n",
      "val Loss: 1.0524 Acc: 0.7763\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 0.9967\n",
      "val Loss: 1.0438 Acc: 0.7806\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9939\n",
      "val Loss: 1.0144 Acc: 0.7978\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.0218 Acc: 0.9950\n",
      "val Loss: 0.9798 Acc: 0.7914\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.0151 Acc: 0.9945\n",
      "val Loss: 0.9067 Acc: 0.7957\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.0195 Acc: 0.9939\n",
      "val Loss: 0.9552 Acc: 0.7978\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.0197 Acc: 0.9945\n",
      "val Loss: 0.9171 Acc: 0.8065\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.0073 Acc: 0.9989\n",
      "val Loss: 0.9368 Acc: 0.7914\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.0097 Acc: 0.9961\n",
      "val Loss: 0.8808 Acc: 0.8065\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.0139 Acc: 0.9956\n",
      "val Loss: 0.8610 Acc: 0.8022\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.0366 Acc: 0.9923\n",
      "val Loss: 0.9450 Acc: 0.7785\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.0085 Acc: 0.9983\n",
      "val Loss: 0.8770 Acc: 0.7892\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.0048 Acc: 0.9989\n",
      "val Loss: 0.9141 Acc: 0.7957\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.0152 Acc: 0.9978\n",
      "val Loss: 0.8558 Acc: 0.8065\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9967\n",
      "val Loss: 0.9292 Acc: 0.8000\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.0074 Acc: 0.9972\n",
      "val Loss: 0.8645 Acc: 0.7978\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.0066 Acc: 0.9983\n",
      "val Loss: 0.8111 Acc: 0.8194\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.0086 Acc: 0.9972\n",
      "val Loss: 0.8461 Acc: 0.8108\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9994\n",
      "val Loss: 0.8241 Acc: 0.8043\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.0065 Acc: 0.9983\n",
      "val Loss: 0.8340 Acc: 0.8151\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.0192 Acc: 0.9961\n",
      "val Loss: 0.8435 Acc: 0.7914\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 0.9978\n",
      "val Loss: 0.8758 Acc: 0.8108\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.0315 Acc: 0.9895\n",
      "val Loss: 0.9246 Acc: 0.7892\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.0092 Acc: 0.9972\n",
      "val Loss: 0.9095 Acc: 0.7871\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.0063 Acc: 0.9989\n",
      "val Loss: 0.8693 Acc: 0.8065\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.0051 Acc: 0.9994\n",
      "val Loss: 0.8896 Acc: 0.8000\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 0.9945\n",
      "val Loss: 0.9023 Acc: 0.8086\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 0.9967\n",
      "val Loss: 0.8434 Acc: 0.8086\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 0.9983\n",
      "val Loss: 0.8731 Acc: 0.8108\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "val Loss: 0.8394 Acc: 0.8258\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.0032 Acc: 0.9989\n",
      "val Loss: 0.8781 Acc: 0.8172\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.0073 Acc: 0.9972\n",
      "val Loss: 0.9487 Acc: 0.8000\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9989\n",
      "val Loss: 0.8612 Acc: 0.8086\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.0023 Acc: 0.9994\n",
      "val Loss: 0.9181 Acc: 0.8043\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "val Loss: 0.9228 Acc: 0.8000\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "val Loss: 0.8849 Acc: 0.8129\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.0025 Acc: 0.9994\n",
      "val Loss: 0.9325 Acc: 0.8022\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.0039 Acc: 0.9989\n",
      "val Loss: 0.9222 Acc: 0.8043\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "val Loss: 0.9733 Acc: 0.8000\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.0027 Acc: 0.9994\n",
      "val Loss: 0.9507 Acc: 0.8129\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.0026 Acc: 0.9994\n",
      "val Loss: 0.9252 Acc: 0.8065\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9994\n",
      "val Loss: 1.0066 Acc: 0.7892\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 0.9967\n",
      "val Loss: 1.0584 Acc: 0.7785\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.0481 Acc: 0.9873\n",
      "val Loss: 1.0492 Acc: 0.8022\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.0148 Acc: 0.9945\n",
      "val Loss: 1.0687 Acc: 0.7935\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.0076 Acc: 0.9983\n",
      "val Loss: 0.9919 Acc: 0.8301\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.0189 Acc: 0.9961\n",
      "val Loss: 1.0480 Acc: 0.7978\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.0189 Acc: 0.9939\n",
      "val Loss: 1.0759 Acc: 0.8065\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.0155 Acc: 0.9945\n",
      "val Loss: 0.9896 Acc: 0.8043\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.0108 Acc: 0.9967\n",
      "val Loss: 0.9645 Acc: 0.7978\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.0072 Acc: 0.9978\n",
      "val Loss: 1.0293 Acc: 0.7935\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.9934\n",
      "val Loss: 1.0322 Acc: 0.7892\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9994\n",
      "val Loss: 1.0348 Acc: 0.7871\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.0075 Acc: 0.9978\n",
      "val Loss: 1.0129 Acc: 0.7935\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 0.9994\n",
      "val Loss: 1.1212 Acc: 0.7699\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.0077 Acc: 0.9978\n",
      "val Loss: 1.0001 Acc: 0.7935\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.0028 Acc: 1.0000\n",
      "val Loss: 1.0316 Acc: 0.8000\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "val Loss: 0.9950 Acc: 0.8108\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 0.9994\n",
      "val Loss: 1.0043 Acc: 0.8000\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.0037 Acc: 0.9994\n",
      "val Loss: 1.0268 Acc: 0.8065\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.0062 Acc: 0.9983\n",
      "val Loss: 1.0323 Acc: 0.7957\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.0127 Acc: 0.9972\n",
      "val Loss: 0.9705 Acc: 0.7935\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.0316 Acc: 0.9928\n",
      "val Loss: 1.0184 Acc: 0.7849\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.0156 Acc: 0.9956\n",
      "val Loss: 1.0788 Acc: 0.7871\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.0079 Acc: 0.9983\n",
      "val Loss: 1.0432 Acc: 0.8000\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.0148 Acc: 0.9950\n",
      "val Loss: 0.9938 Acc: 0.7806\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9978\n",
      "val Loss: 0.9886 Acc: 0.7742\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.0066 Acc: 0.9978\n",
      "val Loss: 0.8906 Acc: 0.8086\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9983\n",
      "val Loss: 0.9391 Acc: 0.7914\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.0078 Acc: 0.9978\n",
      "val Loss: 0.9859 Acc: 0.7849\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.0066 Acc: 0.9983\n",
      "val Loss: 0.9286 Acc: 0.7978\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9983\n",
      "val Loss: 0.9384 Acc: 0.7871\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.0101 Acc: 0.9961\n",
      "val Loss: 1.0400 Acc: 0.7914\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9989\n",
      "val Loss: 1.0103 Acc: 0.7935\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9961\n",
      "val Loss: 1.0310 Acc: 0.7763\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.0330 Acc: 0.9900\n",
      "val Loss: 1.0379 Acc: 0.7849\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.0154 Acc: 0.9950\n",
      "val Loss: 0.9726 Acc: 0.7785\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.0163 Acc: 0.9956\n",
      "val Loss: 1.0046 Acc: 0.7656\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9983\n",
      "val Loss: 0.9918 Acc: 0.7871\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.0054 Acc: 0.9994\n",
      "val Loss: 1.0178 Acc: 0.7892\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.0039 Acc: 0.9994\n",
      "val Loss: 1.0462 Acc: 0.7935\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.0032 Acc: 0.9994\n",
      "val Loss: 0.9816 Acc: 0.7957\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.0127 Acc: 0.9972\n",
      "val Loss: 0.9600 Acc: 0.7957\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 0.9994\n",
      "val Loss: 0.9873 Acc: 0.7957\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.9956\n",
      "val Loss: 1.0754 Acc: 0.7699\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9945\n",
      "val Loss: 1.0024 Acc: 0.7677\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9956\n",
      "val Loss: 1.0274 Acc: 0.7634\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.0104 Acc: 0.9978\n",
      "val Loss: 1.0428 Acc: 0.7785\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.0080 Acc: 0.9972\n",
      "val Loss: 0.9896 Acc: 0.7677\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.0082 Acc: 0.9978\n",
      "val Loss: 1.0468 Acc: 0.7677\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9994\n",
      "val Loss: 0.9832 Acc: 0.7785\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.0023 Acc: 1.0000\n",
      "val Loss: 0.9896 Acc: 0.7828\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 0.9994\n",
      "val Loss: 0.9662 Acc: 0.7892\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.0072 Acc: 0.9989\n",
      "val Loss: 1.0094 Acc: 0.7935\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 0.9961\n",
      "val Loss: 1.0427 Acc: 0.7785\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.0197 Acc: 0.9967\n",
      "val Loss: 1.0168 Acc: 0.7742\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.0064 Acc: 0.9978\n",
      "val Loss: 0.9906 Acc: 0.7785\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.0084 Acc: 0.9978\n",
      "val Loss: 0.9639 Acc: 0.7892\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.0210 Acc: 0.9950\n",
      "val Loss: 1.0152 Acc: 0.7806\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.0070 Acc: 0.9983\n",
      "val Loss: 1.0224 Acc: 0.8043\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.0076 Acc: 0.9989\n",
      "val Loss: 0.9883 Acc: 0.7849\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.0057 Acc: 0.9983\n",
      "val Loss: 1.0334 Acc: 0.7806\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.0159 Acc: 0.9961\n",
      "val Loss: 0.9673 Acc: 0.7892\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.0065 Acc: 0.9978\n",
      "val Loss: 1.0560 Acc: 0.8022\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.0187 Acc: 0.9934\n",
      "val Loss: 1.0666 Acc: 0.7871\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 0.9961\n",
      "val Loss: 1.0727 Acc: 0.8065\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.0139 Acc: 0.9983\n",
      "val Loss: 1.0592 Acc: 0.8022\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.0162 Acc: 0.9972\n",
      "val Loss: 1.0988 Acc: 0.7978\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9994\n",
      "val Loss: 1.0340 Acc: 0.8000\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.0224 Acc: 0.9917\n",
      "val Loss: 1.0530 Acc: 0.8043\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 0.9978\n",
      "val Loss: 1.1338 Acc: 0.7849\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.0185 Acc: 0.9945\n",
      "val Loss: 1.0424 Acc: 0.7742\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.0053 Acc: 0.9983\n",
      "val Loss: 0.9903 Acc: 0.7892\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 0.9989\n",
      "val Loss: 0.9841 Acc: 0.7892\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.0384 Acc: 0.9889\n",
      "val Loss: 1.0687 Acc: 0.7849\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.9928\n",
      "val Loss: 0.9885 Acc: 0.7849\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.0110 Acc: 0.9972\n",
      "val Loss: 1.0125 Acc: 0.7828\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.0276 Acc: 0.9939\n",
      "val Loss: 1.1666 Acc: 0.7806\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 0.9917\n",
      "val Loss: 1.1153 Acc: 0.7892\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9989\n",
      "val Loss: 1.0303 Acc: 0.7957\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.0060 Acc: 0.9989\n",
      "val Loss: 1.0043 Acc: 0.7849\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.0200 Acc: 0.9972\n",
      "val Loss: 1.0213 Acc: 0.7935\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.0092 Acc: 0.9978\n",
      "val Loss: 0.9862 Acc: 0.7957\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9983\n",
      "val Loss: 1.0101 Acc: 0.7935\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 0.9967\n",
      "val Loss: 0.9298 Acc: 0.8022\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.0344 Acc: 0.9928\n",
      "val Loss: 1.0490 Acc: 0.7892\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.0339 Acc: 0.9945\n",
      "val Loss: 0.9553 Acc: 0.7957\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.0072 Acc: 0.9983\n",
      "val Loss: 0.9887 Acc: 0.7828\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.0061 Acc: 0.9989\n",
      "val Loss: 0.9529 Acc: 0.7935\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.0024 Acc: 0.9994\n",
      "val Loss: 0.9872 Acc: 0.7978\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.0017 Acc: 0.9994\n",
      "val Loss: 0.9843 Acc: 0.7849\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.0020 Acc: 1.0000\n",
      "val Loss: 0.9695 Acc: 0.7935\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9972\n",
      "val Loss: 0.9841 Acc: 0.7957\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9950\n",
      "val Loss: 0.9792 Acc: 0.8000\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.0373 Acc: 0.9895\n",
      "val Loss: 0.9845 Acc: 0.8086\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9840\n",
      "val Loss: 1.1625 Acc: 0.7849\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.0163 Acc: 0.9945\n",
      "val Loss: 1.0635 Acc: 0.7828\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.0072 Acc: 0.9983\n",
      "val Loss: 1.0778 Acc: 0.7677\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.0108 Acc: 0.9978\n",
      "val Loss: 1.1525 Acc: 0.7763\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.0175 Acc: 0.9972\n",
      "val Loss: 1.1022 Acc: 0.7785\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 0.9961\n",
      "val Loss: 1.0769 Acc: 0.7828\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9956\n",
      "val Loss: 1.1314 Acc: 0.7699\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.0093 Acc: 0.9978\n",
      "val Loss: 1.0497 Acc: 0.7871\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.0030 Acc: 0.9994\n",
      "val Loss: 1.0715 Acc: 0.7871\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9967\n",
      "val Loss: 1.0460 Acc: 0.7742\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9900\n",
      "val Loss: 0.9348 Acc: 0.7957\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.0127 Acc: 0.9967\n",
      "val Loss: 0.9419 Acc: 0.8129\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.0127 Acc: 0.9989\n",
      "val Loss: 1.0224 Acc: 0.7935\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.0061 Acc: 0.9989\n",
      "val Loss: 0.9823 Acc: 0.7935\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9983\n",
      "val Loss: 0.9965 Acc: 0.8043\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.0164 Acc: 0.9961\n",
      "val Loss: 1.0414 Acc: 0.8022\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.0081 Acc: 0.9983\n",
      "val Loss: 0.9756 Acc: 0.8043\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9961\n",
      "val Loss: 1.0613 Acc: 0.8000\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.0059 Acc: 0.9989\n",
      "val Loss: 1.0524 Acc: 0.7892\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.0026 Acc: 0.9994\n",
      "val Loss: 1.0181 Acc: 0.7957\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.0023 Acc: 1.0000\n",
      "val Loss: 1.0188 Acc: 0.7957\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9983\n",
      "val Loss: 1.0546 Acc: 0.7957\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.0106 Acc: 0.9961\n",
      "val Loss: 1.0605 Acc: 0.8000\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.0061 Acc: 0.9983\n",
      "val Loss: 1.0173 Acc: 0.7978\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.0034 Acc: 0.9994\n",
      "val Loss: 1.0586 Acc: 0.7828\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "val Loss: 1.0496 Acc: 0.7892\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.0028 Acc: 0.9989\n",
      "val Loss: 1.0257 Acc: 0.8000\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.0023 Acc: 1.0000\n",
      "val Loss: 1.0748 Acc: 0.7935\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "val Loss: 1.0923 Acc: 0.7849\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.0019 Acc: 0.9994\n",
      "val Loss: 1.0471 Acc: 0.7957\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.0025 Acc: 0.9994\n",
      "val Loss: 1.0209 Acc: 0.7978\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.0070 Acc: 0.9983\n",
      "val Loss: 1.0320 Acc: 0.8043\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 0.9972\n",
      "val Loss: 1.1222 Acc: 0.7957\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.0060 Acc: 0.9983\n",
      "val Loss: 1.1055 Acc: 0.8086\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.0174 Acc: 0.9961\n",
      "val Loss: 1.1587 Acc: 0.7871\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9950\n",
      "val Loss: 1.0506 Acc: 0.7871\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.0165 Acc: 0.9956\n",
      "val Loss: 0.9831 Acc: 0.7957\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "val Loss: 1.0349 Acc: 0.8000\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9983\n",
      "val Loss: 0.9825 Acc: 0.8022\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.0225 Acc: 0.9945\n",
      "val Loss: 1.0489 Acc: 0.7914\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.0306 Acc: 0.9900\n",
      "val Loss: 1.0854 Acc: 0.7892\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.0097 Acc: 0.9972\n",
      "val Loss: 1.0872 Acc: 0.7806\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.0079 Acc: 0.9978\n",
      "val Loss: 1.0362 Acc: 0.7892\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 1.0000\n",
      "val Loss: 1.0430 Acc: 0.7914\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.0042 Acc: 0.9989\n",
      "val Loss: 1.0421 Acc: 0.8022\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.0040 Acc: 0.9994\n",
      "val Loss: 1.0814 Acc: 0.7914\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.0250 Acc: 0.9956\n",
      "val Loss: 1.1243 Acc: 0.7742\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.0122 Acc: 0.9950\n",
      "val Loss: 1.0684 Acc: 0.7828\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.0059 Acc: 0.9978\n",
      "val Loss: 1.1251 Acc: 0.7785\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.0031 Acc: 0.9994\n",
      "val Loss: 1.1905 Acc: 0.7806\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.0029 Acc: 0.9994\n",
      "val Loss: 1.1199 Acc: 0.7957\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.0027 Acc: 0.9994\n",
      "val Loss: 1.1209 Acc: 0.7828\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 0.9989\n",
      "val Loss: 1.1034 Acc: 0.7914\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.0060 Acc: 0.9983\n",
      "val Loss: 1.1144 Acc: 0.7849\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.0027 Acc: 0.9994\n",
      "val Loss: 1.1066 Acc: 0.7849\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9994\n",
      "val Loss: 1.1666 Acc: 0.7914\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.0030 Acc: 0.9989\n",
      "val Loss: 1.1270 Acc: 0.7849\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.0037 Acc: 0.9994\n",
      "val Loss: 1.0970 Acc: 0.7871\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 0.9994\n",
      "val Loss: 1.1072 Acc: 0.7871\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.0037 Acc: 0.9989\n",
      "val Loss: 1.1180 Acc: 0.7914\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 0.9989\n",
      "val Loss: 1.1477 Acc: 0.7871\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 0.9978\n",
      "val Loss: 1.2013 Acc: 0.7763\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "val Loss: 1.1982 Acc: 0.7957\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.0026 Acc: 0.9989\n",
      "val Loss: 1.1564 Acc: 0.7871\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.0025 Acc: 1.0000\n",
      "val Loss: 1.1311 Acc: 0.7828\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9989\n",
      "val Loss: 1.0939 Acc: 0.7978\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.0134 Acc: 0.9972\n",
      "val Loss: 1.0877 Acc: 0.7892\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "val Loss: 1.0342 Acc: 0.7978\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 0.9994\n",
      "val Loss: 1.0787 Acc: 0.7892\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.0085 Acc: 0.9978\n",
      "val Loss: 1.0454 Acc: 0.7914\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.9945\n",
      "val Loss: 1.1459 Acc: 0.7871\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.0532 Acc: 0.9873\n",
      "val Loss: 1.2168 Acc: 0.7656\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.0209 Acc: 0.9961\n",
      "val Loss: 1.1475 Acc: 0.7849\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.0056 Acc: 0.9983\n",
      "val Loss: 1.1457 Acc: 0.7806\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.0143 Acc: 0.9978\n",
      "val Loss: 1.1681 Acc: 0.7699\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.0137 Acc: 0.9956\n",
      "val Loss: 1.0984 Acc: 0.7699\n",
      "\n",
      "Training complete in 18m 59s\n",
      "Best val Acc: 0.830108\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_name = \"vgg\"\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "model_ft, hist = train_model(model_ft, {'train':train_loader, 'val':val_loader}, criterion, optimizer_ft, num_epochs=500, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "W81Ai8s1mwct",
    "outputId": "9041fadd-f4cc-4742-f274-639b902c76ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=27, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofOCioyT00mk"
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=len(test_dataset),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nThCplNH065J"
   },
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    \n",
    "    data,reference = batch\n",
    "    data = data.view(310, 3, 20, 67)\n",
    "   \n",
    "    data = data.to(device)\n",
    "    predictions = model_ft(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "pZJG5Pjd1X_n",
    "outputId": "f4abad3a-e60e-4a3b-b9ea-f2eb4f4a5ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.7698924731182796\n",
      "Test_accuracy 0.8161290287971497\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfy+dge1Zi6NQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.title('VGG-11')\n",
    "print('Validation accuracy '+str(hist[-1].item()))\n",
    "predictions = torch.argmax(predictions.type(torch.float32).log_softmax(dim=-1),dim=-1).cpu()\n",
    "acc = (reference == predictions).to(torch.float32).mean()\n",
    "print('Test_accuracy '+str(acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "nktfc-chJyZv",
    "outputId": "8de805ac-00fc-47ac-8987-80c82c43e63e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.3419354838709677\n",
      "Test_accuracy 0.32692307233810425\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.title('SqueezeNet 1.0')\n",
    "print('Validation accuracy '+str(hist[-1].item()))\n",
    "predictions = torch.argmax(predictions.type(torch.float32).log_softmax(dim=-1),dim=-1).cpu()\n",
    "acc = (reference == predictions).to(torch.float32).mean()\n",
    "print('Test_accuracy '+str(acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "uF5tRg3YLfBf",
    "outputId": "8fb2ade6-1223-476b-8727-0ddf28734bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.7483870967741936\n",
      "Test_accuracy 0.692307710647583\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.title('Densenet-121')\n",
    "print('Validation accuracy '+str(hist[-1].item()))\n",
    "predictions = torch.argmax(predictions.type(torch.float32).log_softmax(dim=-1),dim=-1).cpu()\n",
    "acc = (reference == predictions).to(torch.float32).mean()\n",
    "print('Test_accuracy '+str(acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oU1AkCdCOIcw"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "translation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
